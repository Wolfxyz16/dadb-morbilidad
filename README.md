# Proyecto DADB

Proyecto en el que se analizan las tasas de Morbilidad Hospitalaria por 100.000 habitantes y estancias medias, seg√∫n el sexo y el diagn√≥stico principal.

> [!IMPORTANT]
> FECHA DE ENTREGA, domingo 11 de mayo a las 23:59 üò±üò±
> FECHA DE PRESENTACI√ìN, miercoles 7 de mayo

## Estructura del proyecto

Esta compuesto por dos ejercicios. Cada uno con su respectiva carpeta.

```bash
‚îú‚îÄ‚îÄ ejercicio1
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ memoria.md
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ poster.pdf
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ src
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ our_code
‚îú‚îÄ‚îÄ ejercicio2
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ memoria.md
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ src
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ our_code
‚îî‚îÄ‚îÄ README.md
```

## Ejercicio 1, an√°lisis de datos p√∫blicos con Hadoop MapReduce.

En este ejercicio, utilizaremos Apache Hadoop para analizar un conjunto de datos p√∫blicos disponible en el portal de datos abiertos del Gobierno de Espa√±a. El objetivo es dise√±ar e implementar uno o varios algoritmos MapReduce para extraer estad√≠sticas significativas y generar visualizaciones que aporten valor anal√≠tico.

### Tareas a realizar

1. Preparaci√≥n de los datos

2. Implementaci√≥n de algoritmos MapReduce, al menos 4 operaciones diferentes que ofrezcan diferentes an√°lisis y estad√≠sticos de valor.

3. Visualizaci√≥n de resultados, generar gr√°ficos significativos.

### Recomendaciones

* Explorar bien el conjunto de datos antes de definir nuestros an√°lisis

* Planificar la arquitectura de nuestra soluci√≥n Hadoop considerando el volumen de datos

* Elegir visualizaciones que realmente aporten valor al an√°lisis.

### Entregables

#### `ejercicio1/src`

* Scripts de preprocesamiento de datos
* Implementaci√≥n de los algoritmos MapReduce
* C√≥digo para la generaci√≥n de visualizaciones (opcional)

#### `ejercicio1/memoria.md`

* Descripci√≥n del conjunto de datos que hemos utilizado
* Metodolog√≠a aplicada y justificaci√≥n
* Descripci√≥n de los algoritmos MapReduce implementados
* An√°lisis detallado de los resultados obtenidos
* Conclusiones y posibles aplicaciones pr√°cticas

#### `ejercicio1/poster.pdf`

* Breve descripci√≥n del conjunto de datos
* Metodolog√≠a aplicada
* Principales resultados y visualizaciones
* Conclusiones m√°s relevantes

---

## Ejercicio 2, ISS

La Estaci√≥n Espacial Internacional (ISS) es una estaci√≥n espacial habitada que orbita la Tierra a 400 km de altura. Es un proyecto internacional entre cinco agencias espaciales: NASA, Roscosmos, JAXA, ESA y CSA.

La ISS ha estado habitada de forma continuada desde el a√±o 2000. Normalmente hay entre 3 y 7 astronautas a bordo realizando trabajos de investigaci√≥n en microgravedad. La ISS realiza una vuelta completa a la Tierra cada 90 minutos. Eso quiere decir, que las y los astronautas a bordo del ISS visualizan en un d√≠a terrestre hasta 16 amaneceres y atardeceres.

Open Notify API es una API p√∫blica y abierta que permite obtener datos en tiempo real relacionados con la ISS y la presencia humana en el espacio.

Mediante este ejercicio, se solicita *calcular cu√°nto se ha movido (en km) la ISS por ventanas de 30 segundos*.

Para ello, se espera seguir la siguiente arquitectura:

![Esquema del ejercicio 2 del proyecto](img/esquema1.jpg) 

### Tareas

1. Desarrollar un script en Python que recoja la informaci√≥n de ubicaci√≥n (latitud y longitud) de la ISS cada 2 segundos y almacene dicha informaci√≥n en un fichero log (`iss_logger.py`).

2. Desarrollo de un agente Apache Flume que recoja la informaci√≥n desde un fichero log y la env√≠a a HDFS.

3. Por √∫ltimo, otro script de Python, en el que mediante la ayuda de Apache Spark Streaming, se recoja la informaci√≥n nueva desde HDFS, y cada 30 segundos calcule la distancia recorrida por la ISS en km.

> [!NOTE]
> Se debe desarrollar en `cloudera` que nos propociona ya toda la infraestructura necesaria. `python`, `flume`, `hdfs`, `yarn`, `spark streaming`.

### Recomendaciones

1. Orden para poner en marcha la arquitectura completa:

    1. Agente Apache Flume
    2. Script de Python que recoge desde Open Notify API la ubicaci√≥n de la ISS cada 2 segundos
    3. Script de Apache streaming

```bash
spark-submit -master yarn-client script.py
```

2. Agente Apache Flume

[TODO]

### Entregables

1. C√≥digo completo con los programas Apache Flume y Apache Spark Streaming.

2. Memoria t√©cnica (formato pdf) que incluya:

    * Descripci√≥n de los datos que se obtienen desde 
