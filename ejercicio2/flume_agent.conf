#flume-ng agent --conf conf --conf-file flume_agent.conf  --name agente -Dflume.root.logger=INFO,console
#python iss_logger.py 
#spark-submit --master yarn-client spark_streaming.py 

# Componentes del agente
agente.sources = r1
agente.sinks = s1
agente.channels = c1

# Configuracion del source
agente.sources.r1.type = exec 
agente.sources.r1.command = tail -F /home/cloudera/dadb-morbilidad/proyecto_ejercicio2/iss_location.log

# Configuracion del sinks
agente.sinks.s1.type = logger

# Configuraci√≥n del sink
agente.sinks.s1.type = hdfs


agente.sinks.s1.hdfs.path = hdfs://localhost:8020/proyecto_ejercicio2
agente.sinks.s1.hdfs.fileType = DataStream
agente.sinks.s1.hdfs.writeFormat = Text
agente.sinks.s1.hdfs.rollInterval = 30 
agente.sinks.s1.hdfs.useLocalTimeStamp = true

# Configuracion del canal
agente.channels.c1.type = memory
agente.channels.c1.capacity = 1000
agente.channels.c1.transactionCapacity = 100

agente.sources.r1.channels = c1
agente.sinks.s1.channel = c1

